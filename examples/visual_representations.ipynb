{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79518a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.hand_visualizations import *\n",
    "DATASET_PATH = \"/Users/christina/.cache/kagglehub/datasets/drgfreeman/rockpaperscissors/versions/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8d697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: How to use different representations in training\n",
    "if __name__ == \"__main__\":\n",
    "    # Your dataset path\n",
    "    dataset_path = \"/Users/christina/.cache/kagglehub/datasets/drgfreeman/rockpaperscissors/versions/2\"\n",
    "    \n",
    "    print(\"Exploring RPS dataset...\")\n",
    "    image_paths, labels, class_images = explore_rps_dataset(dataset_path)\n",
    "    \n",
    "    if image_paths:\n",
    "        print(f\"\\nFound {len(image_paths)} images total\")\n",
    "        \n",
    "        # Visualize samples from each class\n",
    "        print(\"\\nVisualizing sample images from each class...\")\n",
    "        visualize_multiple_samples(class_images, num_samples=3)\n",
    "        \n",
    "        # Process and visualize representations for one sample from each class\n",
    "        print(\"\\nProcessing hand representations...\")\n",
    "        for class_name, images in class_images.items():\n",
    "            if images:\n",
    "                print(f\"\\nProcessing {class_name} example...\")\n",
    "                sample_image = images[0]  # Take first image from each class\n",
    "                representations = visualize_representations(sample_image)\n",
    "                \n",
    "                print(f\"Representation shapes for {class_name}:\")\n",
    "                for key, value in representations.items():\n",
    "                    if isinstance(value, np.ndarray):\n",
    "                        print(f\"  {key}: {value.shape}\")\n",
    "                \n",
    "                break  # Just show one example for now\n",
    "        \n",
    "        # Create label mapping\n",
    "        unique_labels = list(set(labels))\n",
    "        label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        idx_to_label = {idx: label for label, idx in label_to_idx.items()}\n",
    "        \n",
    "        print(f\"\\nLabel mapping: {label_to_idx}\")\n",
    "        \n",
    "        # Convert string labels to integers\n",
    "        numeric_labels = [label_to_idx[label] for label in labels]\n",
    "        \n",
    "        # Example: Create dataset for training\n",
    "        print(\"\\nCreating PyTorch datasets...\")\n",
    "        \n",
    "        # Split data (simple example - you might want stratified split)\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        \n",
    "        train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
    "            image_paths, numeric_labels, test_size=0.2, random_state=42, stratify=numeric_labels\n",
    "        )\n",
    "        \n",
    "        print(f\"Train set: {len(train_paths)} images\")\n",
    "        print(f\"Test set: {len(test_paths)} images\")\n",
    "        \n",
    "        # Create datasets for different representations\n",
    "        transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Example datasets\n",
    "        datasets = {}\n",
    "        for rep_type in ['raw_rgb', 'seg_mask', 'edges']:\n",
    "            datasets[rep_type] = {\n",
    "                'train': RPSRepresentationDataset(train_paths, train_labels, rep_type, transform),\n",
    "                'test': RPSRepresentationDataset(test_paths, test_labels, rep_type, transform)\n",
    "            }\n",
    "        \n",
    "        # Landmarks dataset (different transform)\n",
    "        datasets['landmarks'] = {\n",
    "            'train': RPSRepresentationDataset(train_paths, train_labels, 'landmarks', None),\n",
    "            'test': RPSRepresentationDataset(test_paths, test_labels, 'landmarks', None)\n",
    "        }\n",
    "        \n",
    "        print(\"\\nDatasets created successfully!\")\n",
    "        print(\"Available representations:\", list(datasets.keys()))\n",
    "        \n",
    "        # Test loading a sample\n",
    "        print(\"\\nTesting data loading...\")\n",
    "        for rep_type, dataset_dict in datasets.items():\n",
    "            try:\n",
    "                sample_data, sample_label = dataset_dict['train'][0]\n",
    "                print(f\"{rep_type}: data shape = {sample_data.shape if hasattr(sample_data, 'shape') else type(sample_data)}, label = {sample_label}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading {rep_type}: {e}\")\n",
    "    \n",
    "    else:\n",
    "        print(\"No images found. Please check the dataset path and structure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a602df81",
   "metadata": {},
   "source": [
    "1. Raw RGB Representation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs587_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
